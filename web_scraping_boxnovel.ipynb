{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anurag-anthony/Webscrapping_for_Novels/blob/main/web_scraping_boxnovel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlCbBYjcrxGD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrLxD9Scr78d"
      },
      "outputs": [],
      "source": [
        "def fetch_paragraphs(url_base, start_chapter, end_chapter):\n",
        "    all_paragraphs = []\n",
        "    for i in range(start_chapter, end_chapter + 1):\n",
        "        url = f\"{url_base}{i}\"\n",
        "\n",
        "        try:\n",
        "            # Fetch the website content\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Check if the request was successful\n",
        "            # time.sleep(1)\n",
        "            # Parse the website content and extract <p> tags\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            if url[0:20] == 'https://boxnovel.com':\n",
        "              h = soup.find('div',class_='text-left')\n",
        "              paragraphs = h.find_all('p')\n",
        "            else:\n",
        "              paragraphs = soup.find_all('p')\n",
        "\n",
        "            for paragraph in paragraphs:\n",
        "                all_paragraphs.append(paragraph.get_text())\n",
        "            print(f\"Fetched paragraphs from {url}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"An error occurred while fetching {url}: {e}\")\n",
        "\n",
        "    return all_paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t42ujq1W5Rqb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7AWNk-gsOoq"
      },
      "outputs": [],
      "source": [
        "def replace_content(paragraphs):\n",
        "    formatted_paragraphs = []\n",
        "    for paragraph in paragraphs:\n",
        "        formatted_paragraph = paragraph.replace(\"Use arrow keys (or A / D) to PREV/NEXT chapter\", '')\n",
        "        formatted_paragraph = formatted_paragraph.replace(\"Translator: 549690339\", '')\n",
        "        formatted_paragraph = formatted_paragraph.replace(\"рʟease reading on ΒʘXΝOVEL.ϹΟM\", '')\n",
        "        formatted_paragraph = formatted_paragraph.replace(\"Translator: Exodus Tales  Editor: Exodus Tales\", '')\n",
        "        formatted_paragraphs.append(formatted_paragraph)\n",
        "    print(\"the text hasbin replaced\")\n",
        "    return formatted_paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AFvYNe6sT6R"
      },
      "outputs": [],
      "source": [
        "def save_paragraphs_to_text(paragraphs, output_file):\n",
        "    # Write the content of each <p> tag to the text file\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        for paragraph in paragraphs:\n",
        "            file.write(paragraph + '\\n\\n')\n",
        "    print(f\"Website paragraph content has been saved to '{output_file}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3_7kuvpsXzN"
      },
      "outputs": [],
      "source": [
        "# Base URL and parameters\n",
        "url_base = 'https://freewebnovel.com/creating-heavenly-laws/chapter-'\n",
        "start_chapter = 274\n",
        "end_chapter = 284\n",
        "output_file = 'website_paragraphs.txt'  # Replace with the desired output file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJs692aQscul",
        "outputId": "330e2bd0-cefc-4b96-dbcb-aa73a6158921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-274.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-274.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-275.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-275.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-276.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-276.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-277.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-277.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-278.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-278.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-279.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-279.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-280.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-280.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-281.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-281.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-282.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-282.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-283.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-283.html\n",
            "An error occurred while fetching https://freewebnovel.com/creating-heavenly-laws/chapter-284.html: 403 Client Error: Forbidden for url: https://freewebnovel.com/creating-heavenly-laws/chapter-284.html\n",
            "<class 'list'> 0\n",
            "the text hasbin replaced\n",
            "<class 'list'> 0\n",
            "Website paragraph content has been saved to 'website_paragraphs.txt'.\n"
          ]
        }
      ],
      "source": [
        "# Fetch paragraphs and save to text file\n",
        "paragraphs = fetch_paragraphs(url_base, start_chapter, end_chapter)\n",
        "print(type(paragraphs),len(paragraphs))\n",
        "paragraphs=replace_content(paragraphs)\n",
        "print(type(paragraphs),len(paragraphs))\n",
        "save_paragraphs_to_text(paragraphs, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiu9gQ95sfPX",
        "outputId": "f7df495f-3384-493d-cc27-8d35da1f9fc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://boxnovel.com\n"
          ]
        }
      ],
      "source": [
        "print(url_base[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1JetwnJIo5n"
      },
      "outputs": [],
      "source": [
        "def text_file_concatenation():\n",
        "          def open_text_file(input_file):\n",
        "              with open(input_file, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "\n",
        "          def replace_content(text):\n",
        "            # formatted_text = formatted_text.replace(\"Translator: 549690339\", '')\n",
        "            print(\"The text has been replaced\")\n",
        "            return text.replace(\"1temp123.\", '')\n",
        "\n",
        "          def save_text_file(paragraphs, output_file):\n",
        "              with open(output_file, 'w', encoding='utf-8') as file:\n",
        "                  # Convert the list of paragraphs to a single string\n",
        "                  print(type(paragraphs))\n",
        "                  if type(paragraphs) == list:\n",
        "                    print(\"1\")\n",
        "                    for paragraph in paragraphs:\n",
        "                      file.write(''.join(paragraphs))\n",
        "                  else:\n",
        "                    print(\"2\")\n",
        "                    file.write(''.join(paragraphs))\n",
        "\n",
        "\n",
        "              print(f\"Website paragraph content has been saved to '{output_file}'.\")\n",
        "\n",
        "          #input_file = 'raising ant queen 1.txt'\n",
        "          #input_file2 = 'raising ant queen 1.txt'\n",
        "          #output_file = 'website_paragraphs.txt'\n",
        "\n",
        "          input_file = input(\"enter the name of the old text file\")+'.txt'\n",
        "          input_file2 = 'website_paragraphs.txt'\n",
        "          output_file = input_file\n",
        "          a = open_text_file(input_file)\n",
        "          b = replace_content(a)\n",
        "          c = open_text_file(input_file2)\n",
        "          c = replace_content(c)\n",
        "          print(type(c), type(b))\n",
        "          b=b+'\\n\\n1temp123.\\n\\n'\n",
        "          print(type(b))\n",
        "          # b = b + '\\n\\n1temp123.\\n\\n'\n",
        "          d=b+c\n",
        "          print(type(d))\n",
        "          print(len(d))\n",
        "\n",
        "          # d= b + c\n",
        "          # Save the modified content to the second file\n",
        "          save_text_file(d, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj68r8i6IxOw",
        "outputId": "6d6ba3f1-22b7-4d13-bfb0-de0d56b6c820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the name of the old text fileI'm a Pastor 1\n",
            "The text has been replaced\n",
            "The text has been replaced\n",
            "<class 'str'> <class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "2491863\n",
            "<class 'str'>\n",
            "2\n",
            "Website paragraph content has been saved to 'I'm a Pastor 1.txt'.\n"
          ]
        }
      ],
      "source": [
        "text_file_concatenation()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7u75opPiiGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMilFWIOzvFj4CP2fnsXyPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}